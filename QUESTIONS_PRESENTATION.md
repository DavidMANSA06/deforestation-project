# Questions/RÃ©ponses - PrÃ©sentation Projet DÃ©forestation

## ğŸ¯ Questions GÃ©nÃ©rales sur le Projet

### 1. Quel est l'objectif principal du projet ?
**RÃ©ponse :** DÃ©velopper un systÃ¨me de dÃ©tection automatique de la dÃ©forestation Ã  partir d'images satellites, combinant classification binaire et interprÃ©tabilitÃ© visuelle pour identifier et analyser les zones critiques affectÃ©es.

### 2. Pourquoi ce projet est-il important ?
**RÃ©ponse :** La dÃ©forestation est un enjeu environnemental majeur. Un systÃ¨me automatisÃ© permet :
- Une surveillance continue et Ã  grande Ã©chelle des forÃªts
- Une dÃ©tection prÃ©coce des zones dÃ©forestÃ©es
- Une aide Ã  la dÃ©cision pour les organismes de protection environnementale
- Une rÃ©duction des coÃ»ts et du temps d'analyse manuelle

### 3. Quels sont les deux volets principaux du projet ?
**RÃ©ponse :**
1. **Classification binaire** : Distinguer automatiquement les images "deforested" vs "non-deforested"
2. **InterprÃ©tabilitÃ©** : Identifier visuellement les zones critiques qui influencent les prÃ©dictions via Grad-CAM

---

## ğŸ“Š Questions sur les DonnÃ©es

### 4. Quel dataset utilisez-vous ?
**RÃ©ponse :**
- **Nom :** Duo1111/Deforestation
- **Source :** Hugging Face (open-access)
- **Taille :** ~2 010 images satellites
- **Classes :** 2 catÃ©gories (0=deforested, 1=non-deforested)
- **CaractÃ©ristiques :** Images variÃ©es de diffÃ©rentes zones gÃ©ographiques

### 5. Comment sont rÃ©parties les donnÃ©es (train/val/test) ?
**RÃ©ponse :**
- **Train :** 70% (~1407 images) - pour l'entraÃ®nement du modÃ¨le
- **Validation :** 15% (~302 images) - pour ajuster les hyperparamÃ¨tres
- **Test :** 15% (~301 images) - pour l'Ã©valuation finale

### 6. Les donnÃ©es sont-elles Ã©quilibrÃ©es ?
**RÃ©ponse :** Cette question nÃ©cessite une vÃ©rification. Si dÃ©sÃ©quilibre dÃ©tectÃ©, nous pouvons utiliser :
- Augmentation de donnÃ©es (data augmentation)
- PondÃ©ration des classes dans la fonction de perte
- Techniques de sur/sous-Ã©chantillonnage

### 7. Quelle est la rÃ©solution des images ?
**RÃ©ponse :** Les images sont redimensionnÃ©es Ã  **224Ã—224 pixels** pour Ãªtre compatibles avec les modÃ¨les prÃ©-entraÃ®nÃ©s (ResNet, ViT).

---

## ğŸ¤– Questions sur le ModÃ¨le

### 8. Quel(s) modÃ¨le(s) utilisez-vous ?
**RÃ©ponse :** Nous utilisons **ResNet18** prÃ©-entraÃ®nÃ© sur ImageNet :
- Architecture Ã©prouvÃ©e pour la vision par ordinateur
- Poids prÃ©-entraÃ®nÃ©s permettant le transfer learning
- DerniÃ¨re couche adaptÃ©e pour classification binaire (512 â†’ 2 neurones)

### 9. Pourquoi utiliser un modÃ¨le prÃ©-entraÃ®nÃ© ?
**RÃ©ponse :**
- **Transfer Learning :** Le modÃ¨le a dÃ©jÃ  appris des features gÃ©nÃ©riques sur ImageNet (1M+ images)
- **Performance :** Meilleurs rÃ©sultats avec moins de donnÃ©es
- **Temps :** Convergence plus rapide qu'un entraÃ®nement from scratch
- **EfficacitÃ© :** NÃ©cessite moins de ressources computationnelles

### 10. Quelles sont les alternatives Ã  ResNet18 ?
**RÃ©ponse :**
- **Vision Transformer (ViT)** : Architecture basÃ©e sur l'attention, trÃ¨s performante
- **ResNet50/101** : Versions plus profondes pour plus de capacitÃ©
- **EfficientNet** : Meilleur rapport performance/efficacitÃ©
- **Comparaison possible** pour optimiser les rÃ©sultats

### 11. Comment le modÃ¨le est-il adaptÃ© Ã  votre problÃ¨me ?
**RÃ©ponse :**
```python
model.fc = nn.Linear(model.fc.in_features, 2)  # 512 â†’ 2 sorties
```
La derniÃ¨re couche fully-connected est remplacÃ©e pour produire 2 probabilitÃ©s (deforested, non-deforested).

---

## ğŸ”§ Questions Techniques

### 12. Quelle fonction de perte utilisez-vous ?
**RÃ©ponse :** **CrossEntropyLoss** - Standard pour la classification multi-classes :
- Combine LogSoftmax + NLLLoss
- PÃ©nalise les mauvaises prÃ©dictions proportionnellement Ã  leur erreur
- AdaptÃ© aux problÃ¨mes de classification avec classes mutuellement exclusives

### 13. Quel optimiseur et pourquoi ?
**RÃ©ponse :** **Adam (Adaptive Moment Estimation)** avec learning rate = 1e-4 :
- Adapte automatiquement le taux d'apprentissage pour chaque paramÃ¨tre
- Combine les avantages de RMSprop et SGD avec momentum
- Convergence rapide et stable
- Standard pour le deep learning

### 14. Combien d'epochs d'entraÃ®nement ?
**RÃ©ponse :** Actuellement **5 epochs** pour tester rapidement. Peut Ãªtre augmentÃ© (10-20) selon :
- Convergence de la loss
- Performance sur validation
- Risque d'overfitting

### 15. Quelle taille de batch ?
**RÃ©ponse :** **Batch size = 16** - Compromis entre :
- Vitesse d'entraÃ®nement (plus grand = plus rapide)
- MÃ©moire GPU disponible
- StabilitÃ© de la convergence

---

## ğŸ“ˆ Questions sur l'Ã‰valuation

### 16. Quelles mÃ©triques utilisez-vous ?
**RÃ©ponse :**
- **Accuracy** : Pourcentage de prÃ©dictions correctes
- **Precision** : Taux de vrais positifs parmi les prÃ©dictions positives
- **Recall** : Taux de vrais positifs dÃ©tectÃ©s
- **F1-Score** : Moyenne harmonique de precision et recall
- **Matrice de confusion** : Visualisation des erreurs

### 17. Quelle mÃ©trique est la plus importante ?
**RÃ©ponse :** DÃ©pend du contexte :
- **Recall Ã©levÃ©** si on veut dÃ©tecter toutes les dÃ©forestations (prioritÃ© : ne rien manquer)
- **Precision Ã©levÃ©e** si on veut Ã©viter les fausses alertes
- **F1-Score** pour un Ã©quilibre entre les deux

### 18. Comment validez-vous que le modÃ¨le ne fait pas d'overfitting ?
**RÃ©ponse :**
- Comparaison train accuracy vs validation accuracy
- Si train >> validation â†’ overfitting
- Solutions : dropout, rÃ©gularisation, data augmentation, early stopping

---

## ğŸ” Questions sur l'InterprÃ©tabilitÃ©

### 19. Qu'est-ce que Grad-CAM ?
**RÃ©ponse :** **Gradient-weighted Class Activation Mapping** :
- Technique d'explicabilitÃ© visuelle
- GÃ©nÃ¨re une heatmap montrant les zones de l'image importantes pour la prÃ©diction
- Utilise les gradients de la derniÃ¨re couche de convolution
- Permet de visualiser "oÃ¹" le modÃ¨le regarde pour dÃ©cider

### 20. Pourquoi l'interprÃ©tabilitÃ© est-elle cruciale ?
**RÃ©ponse :**
- **Validation** : VÃ©rifier que le modÃ¨le se concentre sur les bonnes features (vÃ©gÃ©tation, zones dÃ©gagÃ©es)
- **Confiance** : Augmenter la confiance des utilisateurs dans les prÃ©dictions
- **DÃ©bug** : Identifier si le modÃ¨le apprend des biais
- **Insight** : Fournir des informations exploitables pour la surveillance environnementale

### 21. Que montrent les heatmaps gÃ©nÃ©rÃ©es ?
**RÃ©ponse :** Les heatmaps visualisent :
- **Rouge/Chaud** : Zones ayant le plus d'influence sur la prÃ©diction (ex: zones dÃ©boisÃ©es)
- **Bleu/Froid** : Zones avec peu d'influence
- Permettent de valider que le modÃ¨le dÃ©tecte bien la dÃ©forestation et non des artefacts

---

## ğŸš€ Questions sur l'ImplÃ©mentation

### 22. Quelle est la structure du code ?
**RÃ©ponse :**
```
src/
â”œâ”€â”€ data_loader.py    # Chargement et prÃ©paration des donnÃ©es
â”œâ”€â”€ train.py          # EntraÃ®nement du modÃ¨le
â”œâ”€â”€ evaluate.py       # Ã‰valuation (mÃ©triques, confusion matrix)
â”œâ”€â”€ interpret.py      # Grad-CAM et visualisations
â””â”€â”€ visualize.py      # GÃ©nÃ©ration de graphiques
```

### 23. Quels sont les prÃ©requis techniques ?
**RÃ©ponse :**
- **Python 3.8+**
- **PyTorch** : Framework de deep learning
- **torchvision** : ModÃ¨les et transformations d'images
- **timm** : BibliothÃ¨que de modÃ¨les prÃ©-entraÃ®nÃ©s
- **Grad-CAM** : InterprÃ©tabilitÃ©
- **GPU recommandÃ©** (CUDA) pour accÃ©lÃ©rer l'entraÃ®nement

### 24. Combien de temps prend l'entraÃ®nement ?
**RÃ©ponse :**
- **Avec GPU** : ~5-10 minutes pour 5 epochs
- **Avec CPU** : ~30-60 minutes pour 5 epochs
- Variable selon le matÃ©riel disponible

---

## ğŸ“ Questions d'Analyse

### 25. Quels sont les dÃ©fis du projet ?
**RÃ©ponse :**
- **DÃ©sÃ©quilibre potentiel** des classes
- **VariabilitÃ©** des images satellites (saisons, qualitÃ©, rÃ©solution)
- **GÃ©nÃ©ralisation** Ã  de nouvelles rÃ©gions gÃ©ographiques
- **Faux positifs** : zones naturellement dÃ©gagÃ©es vs dÃ©forestation
- **Besoin de GPU** pour entraÃ®nement efficace

### 26. Quelles amÃ©liorations futures sont possibles ?
**RÃ©ponse :**
1. **ModÃ¨les plus performants** : ViT, EfficientNet, modÃ¨les ensemble
2. **Data augmentation** : rotations, flips, ajustements de couleur
3. **DÃ©tection d'objets** : Localiser prÃ©cisÃ©ment les zones dÃ©forestÃ©es (YOLO, Faster R-CNN)
4. **Analyse temporelle** : Comparer des images de diffÃ©rentes dates
5. **DÃ©ploiement** : API web pour utilisation en production
6. **DonnÃ©es supplÃ©mentaires** : Augmenter le dataset

### 27. Quelles sont les applications concrÃ¨tes ?
**RÃ©ponse :**
- **ONG environnementales** : Surveillance des zones protÃ©gÃ©es
- **Gouvernements** : ContrÃ´le des activitÃ©s illÃ©gales
- **Recherche** : Ã‰tudes sur l'Ã©volution de la couverture forestiÃ¨re
- **Entreprises** : VÃ©rification de la conformitÃ© des chaÃ®nes d'approvisionnement

---

## ğŸ’¡ Questions pour la DÃ©mo

### 28. Que montrerez-vous lors de la prÃ©sentation ?
**RÃ©ponse :**
1. **Architecture** du modÃ¨le et pipeline de donnÃ©es
2. **RÃ©sultats d'entraÃ®nement** : courbes de loss et accuracy
3. **MÃ©triques d'Ã©valuation** : accuracy, precision, recall, F1
4. **Matrice de confusion** : analyse des erreurs
5. **Grad-CAM** : heatmaps sur images de test
6. **Comparaison** : images correctement/incorrectement classÃ©es

### 29. Comment prouver que le modÃ¨le fonctionne ?
**RÃ©ponse :**
- **Accuracy > 85%** sur test set
- **Grad-CAM** montrant que le modÃ¨le se concentre sur les bonnes zones
- **Exemples visuels** de prÃ©dictions correctes
- **Analyse d'erreurs** : comprendre les cas difficiles

### 30. Quel est le rÃ©sultat attendu final ?
**RÃ©ponse :** Un systÃ¨me complet capable de :
- Classifier automatiquement des images satellites avec haute prÃ©cision
- Expliquer visuellement ses dÃ©cisions via heatmaps
- Servir de base pour un systÃ¨me de surveillance environnementale
- ÃŠtre Ã©tendu Ã  d'autres problÃ¨mes de tÃ©lÃ©dÃ©tection

---

## ğŸ“ Notes pour la PrÃ©sentation

**Points forts Ã  mettre en avant :**
- âœ… ProblÃ¨me rÃ©el et impactant (environnement)
- âœ… Approche moderne (deep learning + transfer learning)
- âœ… InterprÃ©tabilitÃ© (pas une boÃ®te noire)
- âœ… RÃ©sultats quantitatifs et visuels
- âœ… Potentiel d'extension et dÃ©ploiement

**Ã‰lÃ©ments Ã  prÃ©parer :**
- ğŸ“Š Graphiques de performance
- ğŸ–¼ï¸ Exemples visuels de Grad-CAM
- ğŸ“ˆ Comparaison avant/aprÃ¨s entraÃ®nement
- ğŸ¯ DÃ©monstration sur nouvelles images
